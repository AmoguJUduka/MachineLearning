{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNDGM6azYmXCMbbhK8waSnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmoguJUduka/MachineLearning/blob/main/PersonalProjects/MazeProject_ECE651.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary packages"
      ],
      "metadata": {
        "id": "bulvvsGjZxT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mazelib\n",
        "!pip install pillow\n",
        "!pip install urllib3\n",
        "!pip install scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14s2X7IdW-M7",
        "outputId": "88fe9106-7a99-4825-b37a-3fca3a1a5e8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mazelib in /usr/local/lib/python3.10/dist-packages (0.9.16)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from mazelib) (3.0.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mazelib) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (11.0.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries and packages"
      ],
      "metadata": {
        "id": "JxsvajfdY3ok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mPfIWoU8WkjG"
      },
      "outputs": [],
      "source": [
        "# mazelib API\n",
        "from mazelib import Maze\n",
        "from mazelib.generate.Prims import Prims\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import argparse\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions"
      ],
      "metadata": {
        "id": "SOxJ5eph0D3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MazeGenerator(M=20,N=8):\n",
        "    \"\"\" N is the size\"\n",
        "    M is the number of samples\n",
        "    \"\"\"\n",
        "    mazes = [] # Fixed: Removed extra indentation\n",
        "    for i in range(M):\n",
        "        m = Maze()\n",
        "        m.generator = Prims(N, N)  # creation of N x N maze\n",
        "        m.generate()\n",
        "        mazes.append(m)\n",
        "    return mazes\n",
        "\n",
        "\n",
        "\n",
        "# Visualize the maze\n",
        "def VisualizeMaze(grid):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(grid, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"8x8 Maze Generated with Prim's Algorithm\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
        "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
        "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
        "\n",
        "import sys\n",
        "# Convert numerical arguments to strings\n",
        "sys.argv = ['ipython-input-15-',\n",
        "           '--n_epochs', '1',\n",
        "           '--batch_size', '40',\n",
        "           '--lr', '0.001',\n",
        "           '--b1', '0.5',\n",
        "           '--b2', '0.999',\n",
        "           '--n_cpu', '8',\n",
        "           '--latent_dim', '100',\n",
        "           '--img_size', '32',\n",
        "           '--channels', '1',\n",
        "           '--sample_interval', '400']\n",
        "# Now sys.argv contains only strings\n",
        "\n",
        "\n",
        "opt = parser.parse_args()"
      ],
      "metadata": {
        "id": "m3PVqbpvmiY7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mazes = MazeGenerator()\n",
        "VisualizeMaze(mazes[0].grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "Xilh_DljcMq8",
        "outputId": "3bb307d7-4daa-4561-9e51-a03bce2691a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The grid attribute of the maze contains a 2D array representing the maze, where\n",
        "\n",
        "\n",
        "\n",
        "*   **1** indicates walls\n",
        "*   **0** indicates open paths\n",
        "\n"
      ],
      "metadata": {
        "id": "md3JYQUHa1A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming the Maze Dataset"
      ],
      "metadata": {
        "id": "wF3e9bOy0_Ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MazeDataset(Dataset):\n",
        "    def __init__(self, mazes, transform=None):\n",
        "        self.mazes = mazes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mazes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        maze = self.mazes[idx]\n",
        "        maze_array = np.array(maze.grid, dtype=np.float32)\n",
        "        maze_tensor = torch.FloatTensor(maze_array)\n",
        "        maze_tensor = maze_tensor.unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            maze_tensor = self.transform(maze_tensor)\n",
        "\n",
        "        return maze_tensor\n",
        "\n",
        "# Create transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "\n",
        "maze_dataset = MazeDataset(mazes, transform=transform)\n",
        "\n",
        "# Create dataloader\n",
        "dataloader = DataLoader(\n",
        "    maze_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "53I0s02f0fSz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"images\", exist_ok=True)"
      ],
      "metadata": {
        "id": "fkDSis2c0fQR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check to see if the runtime uses a GPU or CPU (GPU is preferred due to its parallel procesiing capability)"
      ],
      "metadata": {
        "id": "ARWQx6v84ipQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "metadata": {
        "id": "qicgl7Kk0fNR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osvwjsnh0fKo",
        "outputId": "053e48df-7171-44e9-ef74-686cf3e76c84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lMKl3h_H93m4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function initializes the weights of a neural network's layers using a normal distribution, specifically targetting convolutional layers and batch normalization layers in a PyTorch model.\n",
        "\n",
        "This initialization is particularly recommended in the DCGAN paper (Deep Convoluitonal Generative Adversarial Networks)."
      ],
      "metadata": {
        "id": "isKIDs9038a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "0tW1028K0fH1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator Class"
      ],
      "metadata": {
        "id": "vCvuxvSb5VcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.init_size = 2  # size of maze // 4 = 2\n",
        "\n",
        "        # First layer transforms noise to 2x2x128 feature map\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Linear(opt.latent_dim, 128 * self.init_size ** 2)\n",
        "        )\n",
        "\n",
        "        # Convolutional blocks to generate maze\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            # First upsampling: 2x2 -> 4x4\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Second upsampling: 4x4 -> 8x8\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Final convolution to get binary maze\n",
        "            nn.Conv2d(64, 1, 3, stride=1, padding=1),  # 1 channel for binary maze\n",
        "            nn.Sigmoid()  # Use Sigmoid instead of Tanh for binary output (0 or 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Generate initial feature map\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        # Generate maze\n",
        "        maze = self.conv_blocks(out)\n",
        "        return maze"
      ],
      "metadata": {
        "id": "UrRvBGQu0fFB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator Class"
      ],
      "metadata": {
        "id": "JPN4vLsl5uOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [\n",
        "                nn.Conv2d(in_filters, out_filters, 3, stride=2, padding=1),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                nn.Dropout2d(0.25)\n",
        "            ]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(1, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "        )\n",
        "\n",
        "\n",
        "        ds_size = 1\n",
        "\n",
        "        # Final classification layer\n",
        "        self.adv_layer = nn.Sequential(\n",
        "            nn.Linear(64 * ds_size * ds_size, 1),  nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "5E4rGdEt0fB3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = torch.nn.BCELoss()  # Loss Function\n",
        "\n",
        "#Initialize Generator and Discriminator\n",
        "generator = Generator()\n",
        "generator = generator.to(device)\n",
        "\n",
        "discriminator = Discriminator()\n",
        "discriminator = discriminator.to(device)"
      ],
      "metadata": {
        "id": "9R7RuRau0e-9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxQ3epN27bn6",
        "outputId": "d500b33d-319b-4b6d-c322-cf68c4d724f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (l1): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
              "  )\n",
              "  (conv_blocks): Sequential(\n",
              "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): Upsample(scale_factor=2.0, mode='nearest')\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Upsample(scale_factor=2.0, mode='nearest')\n",
              "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "discriminator.apply(weights_init_normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-6cEru10e75",
        "outputId": "9942911a-ec30-4b9d-f281-81ce0530cf45"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout2d(p=0.25, inplace=False)\n",
              "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Dropout2d(p=0.25, inplace=False)\n",
              "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Dropout2d(p=0.25, inplace=False)\n",
              "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (adv_layer): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
        "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
        "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
        "\n",
        "import sys\n",
        "# Convert numerical arguments to strings\n",
        "sys.argv = ['ipython-input-15-',\n",
        "           '--n_epochs', '1',\n",
        "           '--batch_size', '40',\n",
        "           '--lr', '0.001',\n",
        "           '--b1', '0.5',\n",
        "           '--b2', '0.999',\n",
        "           '--n_cpu', '8',\n",
        "           '--latent_dim', '100',\n",
        "           '--img_size', '32',\n",
        "           '--channels', '1',\n",
        "           '--sample_interval', '400']\n",
        "# Now sys.argv contains only strings\n",
        "\n",
        "\n",
        "opt = parser.parse_args()"
      ],
      "metadata": {
        "id": "tBu8gstH8kMe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
      ],
      "metadata": {
        "id": "jEX8aqtq0e5P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "metadata": {
        "id": "xRl-YXaU0e2k"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of Model"
      ],
      "metadata": {
        "id": "6lTXg2Nn8zs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified training loop for maze generation\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, data in enumerate(dataloader):\n",
        "        mazes = data[0]\n",
        "        batch_size = mazes.size(0)\n",
        "\n",
        "        # Ground truths\n",
        "        valid = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_mazes = Variable(mazes.type(Tensor))\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
        "        gen_mazes = generator(z)\n",
        "\n",
        "        # Add maze-specific constraints here if needed\n",
        "        # e.g., connectivity check, wall thickness, etc.\n",
        "\n",
        "        g_loss = adversarial_loss(discriminator(gen_mazes), valid)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        real_loss = adversarial_loss(discriminator(real_mazes), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_mazes.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Print progress\n",
        "        if i % 100 == 0:\n",
        "            print(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %.4f] [G loss: %.4f]\"\n",
        "                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "            )\n",
        "\n",
        "        # Save sample mazes\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            # Convert to binary (0 or 1) before saving\n",
        "            sample_mazes = (gen_mazes.data[:9] > 0.5).float()\n",
        "            save_image(sample_mazes, f\"images/{batches_done}.png\", nrow=3, normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "U8lUMqqW0e0B",
        "outputId": "dd998484-2d07-45dd-ab5a-144862401d96"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-65e5e02b589f>:8: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  valid = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 64, 1, 1])",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-65e5e02b589f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# e.g., connectivity check, wall thickness, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_mazes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-75dbfc843153>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mvalidity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2808\u001b[0m         )\n\u001b[1;32m   2809\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2810\u001b[0;31m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2812\u001b[0m     return torch.batch_norm(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2774\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2777\u001b[0m             \u001b[0;34mf\"Expected more than 1 value per channel when training, got input size {size}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 64, 1, 1])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qhVXr1B0exN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "chH6Mw3Z0eur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AkJnWIsz0erq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XaZj_Lli0eou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xkbSNGEt0eja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvjOzdOS0egv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References**\n",
        "\n",
        "\n",
        "1.   https://github.com/john-science/mazelib/blob/main/docs/API.md\n",
        "2.   List item\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r9G7KIx8cjfD"
      }
    }
  ]
}